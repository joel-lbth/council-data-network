{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# viewing council datasets as a graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE DATAFRAME\n",
    "# source https://standards.esd.org.uk/?uri=list%2Ffunctions&tab=downloads\n",
    "\n",
    "location = '../data/functions_mappedToenglishAndWelshServices.csv'\n",
    "if (os.path.exists(location)):\n",
    "  file = location\n",
    "else:\n",
    "  file = 'https://standards.esd.org.uk/csv?uri=list/functions&mappedToUri=list/englishAndWelshServices'\n",
    "  \n",
    "df = pd.read_csv(file, quotechar='\"')\n",
    "\n",
    "df = df[df.Status == 'Live'][['Level 1','Level 2','Label','Mapped label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a logseq graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 to 19 bursary fund.md\n",
      "Abandoned shopping trolleys.md\n",
      "Abandoned vehicles.md\n",
      "...\n",
      "Zoning.md\n",
      "Zoo licence.md\n",
      "Zoos and farm parks.md\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#  CLEAR FILE SYSTEM OF NETWORK FOR USE IN LOGSEQ GRAPH\n",
    "ls ../pages/ | head -n 3\n",
    "echo ...\n",
    "ls ../pages/ | tail -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE INTERLINKED FILE NETWORK FOR USE IN LOGSEQ GRAPH CONTINUED\n",
    "dir = '../pages/'\n",
    "with open(f'{dir}/index.md', 'w') as ftop:\n",
    "    for l1 in df[~df['Level 1'].isna()]['Level 1'].unique():\n",
    "        ftop.write(f'- [[{l1}]]\\n')\n",
    "        print(f'-1 [[{l1}]]')\n",
    "        with open(f'{dir}/{l1}.md', 'w') as fl1:\n",
    "            for l2 in df[df['Level 1'] == l1][~df['Level 2'].isna()]['Level 2'].unique():\n",
    "                print(f'--2 [[{l2}]]')\n",
    "                fl1.write(f'- [[{l2}]]\\n')\n",
    "                with open(f'{dir}/{l2}.md', 'w') as fl2:\n",
    "                    for l2l in df[~df['Level 2'].isna()][df['Level 2'] == l2]['Label'].unique():\n",
    "                        print(f'---2l [[{l2l}]]')\n",
    "                        fl2.write(f'- [[{l2l}]]\\n')\n",
    "                        with open(f'{dir}/{l2l}.md', 'w') as fl2l:\n",
    "                            for l2lm in df[~df['Level 2'].isna() & ~df['Mapped label'].isna()][df['Label'] == l2l]['Mapped label'].unique():\n",
    "                                print(f'---2lm [[{l2lm}]]')\n",
    "                                fl2l.write(f'- [[{l2lm}]]\\n')\n",
    "                                with open(f'{dir}/{l2lm.replace(\"/\",\" and \")}.md', 'w') as fl2lm:\n",
    "                                    fl2lm.write('')\n",
    "            for l1l in df[(df['Level 1'] == l1) & df['Level 2'].isna() & ~df['Mapped label'].isna()]['Label'].unique():\n",
    "                l1l = l1l.replace('/','_')\n",
    "                print(f'--1l [[{l1l}]]')\n",
    "                fl1.write(f'- [[{l1l}]]\\n')\n",
    "                with open(f'{dir}/{l1l}.md', 'w') as fl1l:\n",
    "                    for l1lm in df[df['Level 2'].isna() & ~df['Mapped label'].isna()][df['Label'] == l1l]['Mapped label'].unique():\n",
    "                        print(f'---1lm [[{l1lm}]]')\n",
    "                        fl1l.write(f'- [[{l1lm}]]\\n')\n",
    "                        with open(f'{dir}/{l1lm.replace(\"/\",\" and \")}.md', 'w') as fl1lm:\n",
    "                            fl1lm.write(f'')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a networkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE AN EDGELIST OF ALL THE CONNECTIONS\n",
    "edgelist = pd.concat([\n",
    "    df[~df['Level 1'].isna() & df['Level 2'].isna() & ~df['Mapped label'].isna()][[\n",
    "        'Level 1', 'Label']].drop_duplicates().rename(columns={'Level 1': 'a', 'Label': 'b'}),  # l1l\n",
    "    df[~df['Level 1'].isna() & ~df['Level 2'].isna()][['Level 1', 'Level 2']\n",
    "                                                      ].drop_duplicates().rename(columns={'Level 1': 'a', 'Level 2': 'b'}),  # l1\n",
    "    df[~df['Level 2'].isna() & ~df['Label'].isna()][['Level 2', 'Label']\n",
    "                                                    ].drop_duplicates().rename(columns={'Level 2': 'a', 'Label': 'b'}),  # l2\n",
    "    df[~df['Level 2'].isna() & ~df['Label'].isna() & ~df['Mapped label'].isna()][[\n",
    "        'Level 2', 'Label']].drop_duplicates().rename(columns={'Level 2': 'a', 'Label': 'b'}),  # l2l\n",
    "    df[df['Level 2'].isna() & ~df['Label'].isna() & ~df['Mapped label'].isna()][[\n",
    "        'Label', 'Mapped label']].rename(columns={'Label': 'a', 'Mapped label': 'b'}),  # l3\n",
    "    df[~df['Level 2'].isna() & ~df['Label'].isna() & ~df['Mapped label'].isna()][[\n",
    "        'Label', 'Mapped label']].rename(columns={'Label': 'a', 'Mapped label': 'b'})  # l4\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN EDGELIST INTO GRAPH\n",
    "G=nx.from_pandas_edgelist(edgelist, \"a\", \"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare to visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PREP GRAPH FOR PYVIS\n",
    "nt = Network(notebook=True, cdn_resources='remote', bgcolor=\"#222222\", font_color=\"white\", select_menu=False, filter_menu=False)\n",
    "nt.from_nx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER TO HTML\n",
    "nt.write_html('data-network.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE GML THAT CAN BE USED IN E.G. GEPHI\n",
    "nx.write_gml(G, \"data-network.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER HTML INSIDE NOTEBOOK\n",
    "# ..TAKES AGES\n",
    "# nt.show('../docs/data-network.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE GRAPH NARROWED BY KEYWORD\n",
    "def topic_graph(topic: str, G):\n",
    "\n",
    "    # define a search term or condition to identify nodes\n",
    "    def match_search_term(node):\n",
    "        # Replace this condition with your own criteria\n",
    "        return search in node  # Example: Nodes with even values\n",
    "\n",
    "    # find descendants of nodes matching the search term\n",
    "    descendants = []\n",
    "    for node in G.nodes():\n",
    "        if match_search_term(node):\n",
    "            descendants.extend(nx.descendants(G, node))\n",
    "\n",
    "    # remove duplicates and convert to a set for uniqueness\n",
    "    descendants = set(descendants)\n",
    "\n",
    "    # plot the descendants\n",
    "    s = G.subgraph(descendants)\n",
    "    ntsub = Network(notebook=True, cdn_resources='remote', bgcolor=\"#222222\", font_color=\"white\", \n",
    "                    select_menu=True, filter_menu=False)\n",
    "    ntsub.from_nx(s)\n",
    "    ntsub.write_html(f'data-network-{search.lower()}.html')\n",
    "\n",
    "    return ntsub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topic_map(search: str, G):\n",
    "    nt = topic_graph(search, G)    \n",
    "    # CREATE FILE AND RENDER HTML INSIDE NOTEBOOK\n",
    "    nt.show(f'data-network-{search.lower()}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "  'Building',\n",
    "  'Planning',\n",
    "  'Housing',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-network-bulding.html\n",
      "data-network-planning.html\n",
      "data-network-housing.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[make_topic_map(i, G) for i in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mv *.html ../docs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
